question_id,topic_id,question_text,option_1,option_2,option_3,option_4,correct_answer,explanation
1,3,Your customer has EC2 instances deployed in private subnets that are not Internet reachable. The EC2 instances are deployed in two availability zones within the same region. They need to use these EC2 instances as the backend of an Internet-facing load balancer. The load balancer must support path-based routing. Which option below should you utilize to achieve the required connectivity?,"Create a public subnet in both of the AZs, create an Application Load Balancer, associate the public subnets with the Application Load Balancer, and add the private EC2 instances to the Application Load Balancer",Add public VIFs to the EC2 instances and then add the instances to an Application Load Balancer,"Create a public subnet in one of the AZs, create a Classic Load Balancer, associate the public subnet with the Classic Load Balancer, and add the private EC2 instances to the Classic Load Balancer","Add an Internet Gateway (IGW) each of private subnets where the EC2 instances are deployed, create a Classic Load Balancer, and add static routes pointing the EC2 instances to the Classic Load Balancer",1,"To use EC2 instances deployed in a private subnets with a load balancer, you will need to create a public subnet in each Availability Zone (AZ) the EC2 instances are deployed in, associate the public subnets with the load balancer, and then add the private EC2 instances to the load balancer. Classic Load Balancers do not support path-based routing. Application Load Balancers do support path-based routing and could be used for the criteria defined here. Adding a public VIF or IGW would be helpful in giving the instances Internet access, but that is not a requirement here."
2,3,Which of the following statements about AWS Direct Connect is FALSE?,Direct Connect virtual interfaces can be reconfigured at any time,On-premises VPN hardware is required for Direct Connect to connect to AWS Virtual Private Cloud,Direct Connect is compatible with all AWS services,Direct Connect allows for access to both AWS services using private IP address space and AWS services using public IP address space from the same connection,2,"AWS Direct Connect is a service that allows users to establish a dedicated connection from an on-premises location to AWS. Direct Connect is compatible with all AWS services and allows users to connect to an AWS VPC without the need for on-premises VPN hardware. By using 802.1q VLANs the dedicated Direct Connect connection can be partitioned into multiple virtual interfaces which allow for access to both AWS services using private IP address space and AWS services using public IP address space from the same connection. If a user’s needs change, Direct Connect virtual interfaces can be reconfigured at any time."
3,3,Your customer has EC2 instances deployed in private subnets that are not Internet reachable. The EC2 instances are deployed in two availability zones within the same region. They need to use these EC2 instances as the backend of an Internet-facing load balancer. Which option below should you utilize to achieve the required connectivity?,"Create a public subnet in both of the AZs, create a Load Balancer, associate the public subnets with the Load Balancer, and add the private EC2 instances to the Load Balancer",Add public VIFs to the EC2 instances and then add the instances to a Load Balancer,"Create a public subnet in one of the AZs, create a Load Balancer, associate the public subnet with the Load Balancer, and add the private EC2 instances to the Load Balancer","Add an Internet Gateway (IGW) each of private subnets where the EC2 instances are deployed, create a Load Balancer and add static routes pointing the EC2 instances to the Load Balancer",1,"To use EC2 instances deployed in a private subnets with a load balancer, you will need to create a public subnet in each Availability Zone (AZ) the EC2 instances are deployed in, associate the public subnets with the load balancer, and then add the private EC2 instances to the load balancer. Either an Application or Classic Load Balancer could be used for the criteria defined here."
4,3,Your on-premises datacenter is connected to your VPC using a DX connection. You have multiple Windows EC2 instances deployed within a private subnet in your VPC. You have configured the instances' security group rules to allow for RDP access from your datacenter so you can access the instances for administration. You would like to further harden the configuration and mitigate the risk of man-in-the-middle (MITM) attacks.Which of the following should you implement to mitigate the risk of MITM attacks?,Publicly trusted X.509 certificates,SSL encryption of the RDP connection,EV SSL Certificates,Change the default RDP port,1,"By default, Windows RDP uses untrusted, self-signed certificates. Publicly trusted X.509 certificates can be used to ensure you communicate directly with the Windows instance as opposed to a “man-in-the-middle”. RDP connections establish an underlying SSL/TLS connection, so manual SSL encryption of the RDP connection would be unnecessary. EV SSL Certificates are used for websites. Changing the default RDP port would be “security by obscurity” at best, but would not inherently mitigate MITM attacks."
5,3,"A customer needs to allow EC2 instances deployed across 3 VPCs (VPCs A, B, & C) access to a variety of services and applications at an on-premises datacenter. There is a requirement to have only one VPN connection to the datacenter. There is no sustainable method available for replicating some of the services in AWS. There are no overlapping CIDR ranges at any of the 3 VPCs or the data center network. Which of the solutions below would be best suited for establishing connectivity between VPCs A, B, & C and the on-premises datacenter?","Configure a VPN connection between a 4th VPC and the datacenter, create VPN connections between this VPC and VPCs A, B, & C, use dynamic routing to allow the VPCs A, B, & C to access the datacenter network","Configure a VPN connection between a 4th VPC and the datacenter, create VPC Peering connections between this VPC and VPCs A, B, & C, use static routing to allow the VPCs A, B, & C to access the datacenter network","Configure a VPN connection between a 4th VPC and the datacenter, create VPC Peering connections between this VPC and VPCs A, B, & C, use dynamic routing to allow the VPCs A, B, & C to access the datacenter network","Configure a  4th VPC with a LAG connection to VPN device datacenter network, establish VPC Peering connections between this VPC and VPCs A, B, & C, and create dynamic routes to allow the VPCs A, B, & C to access the datacenter network",1,"A single “Transit VPC” connected via VPN to the datacenter network and VPN connections between VPCs A, B, & C and the Transit VPC would allow for the desired connectivity. Dynamic routing the preferred routing method for this configuration. VPC Peering would not allow for transitive routing. a LAG would be used for a DX connection."
6,3,"You have 4 Direct Connect (DX) connections to your VPC from your Chicago, Boston, Houston, and Orlando offices. Your VPC’s address range is 10.20.0.0/16. You are using BGP routing. You would like to ensure AWS uses the Chicago connection to reach the IP addresses ranging from 10.20.30.0-10.20.30.127 on your network. The other three locations are currently advertising the following routes:
Boston: 10.20.0.0/16 AS 65000
Houston: 10.20.30.0/24 AS 65000 65000
Orlando: 10.20.30.254/32 AS 65000 65000  65000
Which of the following routes could you advertise from your Chicago connection to ensure AWS uses it to access IP addresses ranging from 10.20.30.0-10.20.30.127?",10.20.30.128/26 AS 65000,10.20.128.0/17 AS 65000,10.20.30.0/25 AS 65000 65000 65000,10.20.30.0/23 AS 65000 65000,3,"AWS will choose the most specific route first. If routes are equal after checking for the most specific routes, AWS will use AS path prepending to determine which route is preferred. In this example, 10.20.30.0/25 is more specific than 10.20.30.0/24 and 10.20.0.0/16, so AS path prepending will not matter. The other options are either outside of the address range in question (10.20.30.128/26 and 10.20.128.0/17) or less specific than the route advertised by Houston (10.20.30.0/23). The route advertised from Orlando, 10.20.30.254/32, identifies a single IPv4 address that is outside of the range in question."
7,3,You recently deployed a File Storage Gateway solution for a customer that expands their on-premises storage capacity into the AWS Cloud. There is a requirement to only allow NFS clients with IPv4 addresses between 192.168.1.1 and 192.168.1.14 to mount to a specific file share. These NFS clients have a subnet mask of 255.255.255.0. Which of the entries to the “Allowed clients” list for that file share in the AWS Storage Gateway Console best meets the requirement?,192.168.1.0/28,192.168.1.0/27,192.168.1.0/29,192.168.1.0/24,1,"It is recommended to change the allowed client settings for Storage Gateway file shares. Otherwise, any client on the network could mount to the file share. In this example, 192.168.1.0/28 would include IP addresses ranging from 192.168.1.0 to 192.168.1.15 (with the .0 address reserved as the network address and the .15 reserved as the broadcast address, only the addresses between  .1 and .14 remain). This meets the requirement without allowing additional IP addresses to mount the file share. The /29 suffix would not allow all the IP addresses between 192.168.1.1 and 192.168.1.14 to mount the file share. The /24 and /27 suffixes would allow additional IP addresses to mount the file share. The 255.255.255.0 (/24) subnet mask configured on the clients does not impact what ranges can be defined in the “Allowed clients” list."
8,3,"A customer you configured a Direct Connect (DX) connection for would like to send traffic from a VPC in the US-East-1 region over their corporate network backbone for auditing and on to a VPC in US-West-1 region. The configuration uses dynamic BGP routing. After updating the routing tables, traffic from the US-East-1 VPC is not reaching the US-West-1 VPC. Both VPCs can still access the corporate network. The private IPv4 address range for the VPC in US-East-1 is 172.16.0.0/16 and the private IPv4 address range for the VPC in US-West-1 is 172.17.0.0/16. Which of the following reasons is most likely to be the cause of traffic from the US-East-1 VPC not reaching the US-West-1 VPC?",The described configuration is transitive routing and will not work,The VGWs in US-West-1 and US-East-1 are advertising the same AS number,The VGWs in US-West-1 and US-East-1 are advertising overlapping IP address ranges,The MED on the corporate router is too low,2,"In a BGP environment, if a router sees the same AS number it has in an AS_PATH, it will reject the traffic as the same AS number suggests a loop. In this scenario, the only logical possibility presented is that the AS numbers advertised from US-West-1 and US-East-1 are the same. The described configuration is possible if the routing is properly configured. The MED on the corporate router being “too low” would not be an issue as a lower MED equates to a more preferred route. There is no information to suggest that US-West-1 and US-East-1 are advertising overlapping IP address ranges and since the corporate network can reach both VPCs without issue, this option is even less likely."
9,3,Route 53 is the DNS service for your domain. You would like to access your RDS DB instance using the FQDN “mysitesdb.mycorp.com” as opposed the default FQDN “yourrdsdb.xcvee3b2c3d41134.us-west-1.rds.amazonaws.com” it was assigned. What record should you update to make this possible?,A,AAAA,CNAME,MX,3,"A CNAME record is a DNS record that maps an “alias name” (in this example “mysitesdb.mycorp.com”) to a “canonical name” (in this example “yourrdsdb.xcvee3b2c3d41134.us-west-1.rds.amazonaws.com”). An A record maps IPv4 addresses to domain names, an AAAA record maps IPv6 records to domain names, and a MX record specifies an email server."
10,3,Which of the following routes will AWS prefer if all are broadcast to the same virtual private gateway?,10.10.0.0/16 AS 64511,10.10.10.0/24 AS 64511 AS 64511,0.0.0.0/0 ,10.10.10.0/24 AS 64511,4,"AWS will always prefer the most specific route. If there is not a single most specific route, AS path prepending will be used to determine the preferred route, with the shorter path being preferred. In the example, 10.10.10.0/24 is the most specific route and AS 64511 is shorter than AS 64511 AS 64511."
11,3,You are establishing an IPv6 VPC peering connection between VPC A and VPC B. The name of your VPC Peering connection is pcx-12345678. The IPv6 address range of VPC A is 2001:db8:7589:aa00::/56. The IPv6 address range of VPC B is 2001:db8:4321:bb00::/56. Which of the following entries should be made to VPC A’s route table?,Destination: 2001:db8:4321:bb00::/56 Target: 2001:db8:7589:aa00::/56,Destination: 2001:db8:4321:bb00::/56 Target: pcx-12345678,Destination: 2001:db8:7589:aa00::/128 Target: pcx-12345678,"The configuration as described is an invalid VPC Peering connection, IPv6 is not supported with VPC Peering",2,"VPC Peering does support IPv6. In this example, VPC A’s route table will require an entry that routes traffic destined for VPC B’s IPv6 address range (2001:db8:4321:bb00::/56) to the VPC Peering connection (pcx-12345678). A /128 CIDR range specifies a single IPv6 address."
12,3,"You have Linux EC2 instances deployed in 2 VPCs.
 VPC A has an IP address range of 10.20.30.0/24. VPC B has an IP address range of 10.20.31.0/24. The DNS servers supplied by the DHCP options for both subnets reside in VPC A. VPC B cannot ping the hostnames of instances in VPC A. Instances in VPC A can ping the hostnames of other instances in VPC A. VPC B can ping the IPv4 addresses of the DNS servers. Other than the DNS servers, all the instances have dynamically assigned IPv4 addresses.
Which of the following is most likely the cause?",IGMP is disabled on the instances in VPC A,UDP port 53 outbound is blocked on VPC B,ICMP is disabled on the instances running in VPC A,UDP port 67 outbound is blocked on VPC B,2,"Based on the symptoms, it seems that instances in VPC B cannot resolve the hostnames of the instances in VPC A. This would most likely be caused by access to a DNS server being blocked. DNS queries occur on UDP (or in certain circumstances TCP) port 53. UDP Port 67 is used by DHCP servers. Since ping is working under certain circumstances, ICMP is not disabled. IGMP is not used for ping."
13,3,Return traffic to all EC2 instances in a VPC's new public subnet is somehow blocked. You would like to ensure that return traffic from all potential clients is received moving forward. Which port range should you allow to ensure that return traffic from all potential clients is received?,1024-65535,1-1024,1024-50000,1-65535,1,"Return traffic is received on ephemeral ports. The ephemeral ports used may vary from client to client, the entirety of the ephemeral port range is 1024-65535. Allowing ports outside of that range would be unnecessary. Blocking ports within that range would potentially block return traffic from some clients. In practice, to cover the different types of clients that might initiate traffic to public-facing instances in your VPC, you can open ephemeral ports 1024-65535. However, you can also add rules to the ACL to deny traffic on any malicious ports within that range. Ensure that you place the deny rules earlier in the table than the allow rules that open the wide range of ephemeral ports."
14,3,"You have just provisioned an Application Load Balancer to distribute traffic to your website among a cluster of EC2 instances in the same subnet of a VPC. When you attempt to browse to your site, you are receiving HTTP 504: Gateway Timeout errors. Which of the following is a likely cause of the errors?",Your browser is closing the connection with the load balancer before the idle timeout period passes ,The NACL for the subnet where the EC2 instances are deployed does not allow outbound traffic for TCP ports 1024-65535,Your browser is sending a malformed HTTP request,The security group attached to the EC2 instances behind the load balancer does not allow outbound traffic on TCP ports 1-1023,2,"If the targets for an Application Load Balancer cannot allow traffic from the targets to the load balancer nodes on ephemeral ports (1024-65535), it is likely that an HTTP 504: Gateway Timeout will be returned when users make HTTP requests. It would be unnecessary to allow outbound traffic from the EC2 instances on ports 1-1023 in this scenario. If the issue was related to the client, a 4XX error would be expected."
15,3,"Your company has multiple EC2 instances and S3 buckets across multiple AWS regions that are used to serve a web application that is in the proof of concept stages. Users from all over the world will be accessing the application. You are a member of the security team and you have been tasked with ensuring that the infrastructure is resilient against SYN floods. Your first task is to list Amazon Web Services and features you can use, either individually or collectively, to mitigate your risk to SYN floods. 
Which of the following will help mitigate SYN flood attacks? (Choose 3 answers)",Amazon CloudFront,AWS WAF,NACL,Amazon Elastic Load Balancing,"1, 2, 4","A SYN flood works by sending many SYN messages to a TCP port that is open for a legitimate purpose. Creating a NACL to block traffic would not be an ideal strategy, as it would prevent legitimate users from accessing the application. An ELB would only accept well-formed TCP connections, which helps mitigate the impact of SYN floods. You can use a WAF in conjunction with CloudFront to detect and filter malicious activity like SYN floods."
16,3,"A customer is using a NAT Gateway to allow a cluster of EC2 instances on a private subnet in their VPC to access an S3 bucket in the same region. After a recent uptick in usage, the customer noticed that data transfer charges rose beyond what they expected. The customer has requested that you find a solution that minimizes data transfer costs without exposing the EC2 instances to the Internet directly. Which option best meets the requirements?",Use a NAT Instance instead of the NAT Gateway and update the routing table for the private subnet to route traffic to the S3 bucket to the NAT Instance,Use CloudFront to cache frequently accessed data,Create a VPC Endpoint for the S3 bucket and update the routing table for the private subnet to route traffic to the S3 bucket to the VPC Endpoint,Create a DX connection between the S3 bucket and the private subnet,3,"A VPC endpoint enables you to establish a private connection between a VPC and other AWS resources. Transfers between S3 and AWS resources in the same region are free. Therefore, in this scenario using a VPC Endpoint would save on data transfer costs when compared to a NAT Gateway. A NAT instance would have similar transfer costs to a NAT Gateway. Caching data using CloudFront would not reduce the transfer costs as dramatically as using a VPC Endpoint, and depending on the type of data being transfer may have no or limited impact on costs. A Direct Connect (DX) connection would not be useful in connecting a private VPC subnet to an S3 bucket."
17,3,A client would like to deploy a cluster of EC2 instances for a machine learning project. The instances will be constantly communicating with one another over the network. There is an emphasis on maximizing throughput and minimizing latency in the application. High availability is not a requirement. Which solution best meets the requirements.,"Create a cluster placement group, and deploy extra-large accelerated computing instances with Enhanced Networking enabled and private IPv4 addresses into the placement group.",Deploy an evenly distributed number of extra-large accelerated computing instances with Enhanced Networking enabled and public VIFs between two availability zones.,Create a spread placement group and deploy extra-large T3 burstable instances and private IPv4 addresses in the placement group.,Deploy an evenly distributed number of extra-large T3 burstable instances and private IPv4 addresses evenly across two availability zones.,1,"Cluster placement groups are logical groupings of instances in the same AZ. AWS recommends placement groups for applications that can benefit from low latency and/or high network throughput be deployed in a cluster placement group. Deploying instances into two separate Availability Zones would place them on separate hardware, decreasing performance relative to instances in a cluster placement group.Performance in Placement Groups is optimized when instances communicate using private IP addresses. P2 instances are optimized for accelerated computing and would be preferred over the T3 instances (which do not support Enhanced Networking) for this application."
18,3,"You have a Direct Connect Endpoint connecting an EC2 instance in the US West region to your on-premises network in California via an AWS partner in the region. Currently, the Direct Connect Endpoint has 9 virtual interfaces. You would like to add 3 more virtual interfaces configured similarly to the first 9 which were provisioned using the AWS Direct Connect console. Which of the steps below should you take first?",Contact AWS to request an increase on the limit for virtual interfaces on your Direct Connect Endpoint,Login to the AWS Direct Connect Console and begin provisioning the additional virtual interfaces,"You cannot configure more than 10 virtual interfaces on a Direct Connect Endpoint, so a new Direct Connect Endpoint will need to be provisioned",Enable Auto Negotiation on your on-premises router,2,A Direct Connect Endpoint can have up to 50 virtual interfaces. This limit cannot be exceeded. Virtual interfaces for a Direct Connect Endpoint can be provisioned using the Direct Connect Console. A prerequisite for a Direct Connect connection is disabling Auto Negotiation on the customer end.
19,3,"You have configured a CloudFront distribution with the URL images.yoursite.com to distribute .jpeg files from an S3 bucket named yourbucket.s3.amazonaws.com. The S3 bucket is not publicly accessible. You have configured origin access control (OAC) to grant CloudFront access to all objects in the bucket.However, you receive several errors denying access when visiting images.yoursite.com on your browser.To troubleshoot the issue, you use Dig and receive the following output:> dig images.yoursite.com; <<> DiG 9.3.3rc2 <<> images.yoursite.com;; global options:	printcmd;; Got answer:;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 15917;; flags: qr rd ra; QUERY: 1, ANSWER: 9, AUTHORITY: 2, ADDITIONAL: 0;; QUESTION SECTION:;images.yoursite.com. IN A;; ANSWER SECTION:images.yoursite.com. 10800 IN	CNAME	yourbucket.s3.amazonaws.com.Which steps would most likely resolve the access denied errors in the most secure fashion? Select two choices.",Create a bucket policy to allow public access to the entire S3 bucket,Update the CNAME record,Update the A record,Create a bucket policy to allow public access only to the specific objects to be displayed at images.yoursite.com,"2, 4","When using CloudFront to distribute content from an S3 bucket, the CNAME record should point to the CloudFront distribution’s domain name, not your S3 bucket. In this scenario, modifying the bucket policy would be unnecessary since there is already origin access control to grant CloudFront access to all objects in the bucket. Updating the A record (which maps IPv4 addresses to domain names) would not be helpful in this scenario. "
20,3,"Your customer has a web application and database running in a VPC. They would like to add IPv6 support both for the web application and database. The VPC is split into two subnets. Subnet 2 has an IP address range of 10.100.101.0/24 and hosts the DB instance with a Private IPv4 address of 10.100.101.5. Subnet 2 will require only outbound IPv6 access. Currently, Subnet 2 has outbound IPv4 access through a NAT Gateway. Which of the following solutions should you implement for Subnet 2?","Enable IPv6 on the NAT Gateway, add a static route to point all IPv6 traffic on Subnet 2 to the NAT Gateway, add rules to the security group for the DB instance that block all inbound IPv6 traffic",Add a static route pointing all IPv6 traffic on Subnet 2 to the NAT Gateway,Add an Internet Gateway (IGW) to Subnet 2 and add a static route to point all IPv6 traffic on Subnet 2 to the IGW,Add an Egress-Only Internet Gateway (EIGW) to your VPC and add a static route to point all IPv6 traffic on Subnet 2 to the EIGW,4,An EIGW is designed to only allow outbound IPv6 traffic. NAT Gateways do not support IPv6. An IGW could be leveraged to work but would require additional unnecessary configuration when compared to an EIGW.
21,3,"Your customer has a number of EC2 instances deployed in an auto scaling group. The auto scaling policies scale up and down based on CPU utilization. The demand on the instances is highly variable, so auto scaling has proven to be quite useful in the application. After the latest spike in traffic, an EC2 instance that served as the master node for a Hadoop cluster was terminated when CPU utilization went back down. The customer needs to prevent this from occurring again. Which solution should you recommend?",Increase the cooldown period for the auto scaling group,Enable scale in protection on the EC2 instance in question,Disable auto scaling and “right size” the EC2 instances to handle the highest traffic levels expected,Increase the Desired Capacity for the auto scaling group,2,"Enabling scale in protection on the instance would stop it from being terminated when auto scaling policies scale down. Disabling auto scaling would be overkill and is not desirable given that it serves a logical purpose in this scenario. Increasing the cooldown period or Desired Capacity may prevent the instance from being terminated depending on other variables, but it is not a surefire way to prevent termination long term."
22,3,"Assuming default settings are still in place on the account, what would the IP address of the Amazon Provided DNS server be on a newly created VPC with a network range of 172.20.0.0/16?",172.20.255.254,172.20.0.100,172.20.0.2,172.20.100.100,3,"Assuming default settings are still in place on the account, what would the IP address of the Amazon Provided DNS server be on a newly created VPC with a network range of 172.20.0.0/16?"
23,3,You have configured a Direct Connect (DX) connection for a customer and now need to provision the virtual interfaces to begin using the connection. The customer has 12 S3 buckets and 2 VPCs with 12 EC2 instances on each VPC. All AWS resources are in the same region. Which option below best describes the minimum number of virtual interfaces that will need to be created for all AWS resources to have access to the DX connection?,"3, one public virtual interface for the S3 endpoints and 2 private virtual interfaces for the VPCs","36, one private virtual interface for each S3 endpoint and EC2 instance","1, one public virtual interface for all the resources in the same region","25, one public virtual interface for the S3 endpoints and one private virtual interface for each EC2 instance",1,A public virtual interface is required to connect AWS public endpoints (like S3 for example) to a DX connection. One public virtual interface can be used for all public IP addresses in a region. A private virtual interface is required for each VPC to connect to a DX connection. EC2 instances within a VPc would not need to have a dedicated virtual interface allocated to them.
24,3,"Your customer will be storing critical data in S3 buckets. In addition to a highly restrictive bucket policy, they would like to encrypt the data prior to loading it to the buckets. The customer prefers not to store its master encryption keys within AWS.Which of the following options would it be best to leverage to encrypt the data given the requirements?",CSE-C,CSE-KMS,SSE-S3,SSE-KMS,1,"Given the requirement to encrypt the data prior to loading it to the S3 buckets, server-side solutions like SSE-S3, SSE-KMS, and DSSE-KMS would not meet the requirements. While a KMS-Managed KMS key would allow for client-side encryption, it would not keep the master key out of AWS. Using a Client-Side Encryption Customer Managed key (CSE-C) would allow for client-side encryption and keep the master key out of AWS."
25,3,You are tasked with configuring Route 53 for use with EC2 instances across multiple regions that are used for a customer’s website. The customer would like to route traffic based upon the location of the website’s visitors so visitors from specific regions can be presented with specific content. Which of the following would be best suited to meet the requirement?,"A geolocation routing policy
",A region based routing policy,EDNS0,DynDNS ,1,"A Geolocation routing policy would allow Route 53 to route queries based upon the location of users. DynDNS is  used to automatically update DNS records.  EDNS0 can be used to improve the accuracy of geolocation routing, but is not a routing policy in and of itself. Region based is not a valid Route 53 routing policy type. "
26,3,You use CloudFormation to manage your application stacks and create templates. You have configured a template for an Application Load Balancer that will be useful in a number of stacks. What method should you use to deploy the Application Load Balancer template to multiple stacks?,Copy/paste the template on an as-needed basis,Turn the template into a nested stack,Store the template on a Git server and use CodePipeline to deploy it to other stacks,Store the template on a Git server and create custom scripts to install it as needed,2,"Nested stacks allow you to reference a template from within another template and help simplify the update process as any time the nested stack template is updated, any stack that uses it will receive the updates (once the stack is updated). Copy/pasting the template on an as-needed basis adds an element of human error to the process and is difficult to track. Adding a Git server to the scenario adds unneeded layers of complexity. "
27,3,"Your customer is using basic monitoring with CloudWatch. They have configured an auto scaling policy to deploy new instances when CPU utilization reaches 80%. They have found that, on many occasions a second instance is deployed when one instance would have been sufficient. It appears that the second instance is being deployed before the CloudWatch metrics update. The customer would like to prevent the second instance from deploying unless necessary, but also wants to avoid additional charges to their AWS bill. Which of the following solutions should you recommend?",Enable detailed monitoring of the instances in CloudWatch,Increase the auto scaling cooldown time to 600 seconds,Use OpsWorks for Chef Automate,Configure CloudWatch alerts for CPU utilization and manually deploy the instances,2,"CloudWatch basic monitoring makes data available automatically every 5 minutes at no charge. The default auto scaling cooldown time is 300 seconds (5 minutes). It is likely that in the situations where the second instance was deployed, the monitoring data was not yet up to date. Extending the cooldown time to make the auto scaling action wait 10 minutes would likely mitigate this discrepancy. Enabling detailed monitoring would also likely resolve the issue, but it would led to an incur charges that the customer wants to avoid. Manually deploying the instances is not sustainable. OpsWorks for Chef Automate is overkill given the requirements and would incur charges that the customer wants to avoid."
28,3,You are the network engineer responsible for a VPN connection between a VPC’s virtual private gateway (VGW) and your on-premises VPN device (customer gateway). You are attempting to establish the IPsec tunnel between the two devices. Your customer gateway is on the AWS list of “Customer Gateway Devices We've Tested”. NAT-T is not being used. You have configured both the VGW and customer gateway and are now attempting to establish the IPsec tunnel between them. Phase 1 (IKE exchange) is successful. Phase 2 (IPsec phase) fails. You have tried multiple times with the same results. You have ruled out incompatible IKE versions or encryption methods as the cause. Which option below should you check first?,Verify you can ping the customer gateway,Verify UDP port 500 is not blocked,Verify UDP port 4500 is not blocked,Verify protocol 50 is not blocked,4,"Protocol 50 being blocked is the only option listed that would impact phase 2 but not phase 1. If UDP port 500 was blocked, phase 1 would have failed. UDP port 4500 would only be required if NAT-T was used. Ping would be used to verify network connectivity to the customer gateway which is confirmed by the fact phase 1 was successful."
29,3,A customer you configured a Direct Connect (DX) connection for would like to send traffic from a VPC in the US-East-1 region over their corporate network backbone for auditing and on to a VPC in US-West-1 region. Via BGP the US-East-1 region virtual private gateway (VGW) is advertising an AS number of AS 7224. The corporate Cisco router is advertising an AS number of AS 64511. The VGW in US-West-1 is advertising an AS number of AS 7224. The VGW at US-West-1 is rejecting the traffic originating from US-East-1. Which option below would best resolve the issue?,Use VPC Peering to connect the two VPCs,Create a software VPN connection between the two VPCs,Use AS-Override on the corporate router,Create an EIC Endpoint on the corporate network and configure security groups to allow inbound connections from US-East-1 and outbound connections to US-West-1,3,"In a BGP environment, if a router sees the same AS number it has in an AS_PATH, it will reject the traffic as the same AS number suggests a loop. In this scenario, enabling AS-Override on the corporate router would advertise AS 64511 AS 64511 to the VGW at US-West-1 instead of AS 64511 AS 7224, allowing the traffic to be accepted. VPC Peering or a software VPN connection would not meet the requirement for routing the traffic through the corporate router. An EIC Endpoint would not be a practical solution for this use case. "
30,3,"Your account has 3 VPCs deployed in the same region.
The IPv4 address ranges of the VPCs are:
VPC A 172.22.0.0/16
VPC B 10.3.0.0/16
VPC C 10.4.0.0/16
VPC B and VPC C are already connected through VPC peering connection (PCX) named pcx-abcxyz. VPC A has resources that VPC B and VPC C must access. Which of the options below best achieves the objective of allowing VPC B and VPC C to access VPC A?",Connect VPC A to pcx-abcxyz,Add static routes to VPC A with Targets of 10.3.0.0/16 and 10.4.0.0/16 and a Destination of pcx-abcxyz,Connect VPC A to VPC B using VPC Peering and allow VPC C to access VPC A through VPC B.,Create separate VPC Peering connections between VPC A & VPC B and VPC A & VPC C,4,"Creating separate VPC Peering connections between each VPC is required for Peering 3 VPCs together. Transitive routing is not supported in VPC Peering so VPC C could not reach VPC A through VPC B. A new VPC Peering connection is required for connecting additional VPCs, so connecting VPC A to pcx-abcxyz is not a viable option. Adding a static route to VPC A that points to pcx-abcxyz would not work as pcx-abcxyz is not connected to VPC A."
31,3,You are assisting a customer with the configuration of a customer gateway to be used to establish a VPN connection to a Virtual Private Gateway for access to a VPC. The customer gateway has a public static IPv4 address that is behind a NAT and the device is advertising NAT-T. Firewall rules allowing traffic over what port will be required for NAT-T to function properly?,UDP port 4500,UDP port 50,TCP port 500,TCP port 50,1,"In order for NAT Traversal (NAT-T) to function properly, firewall rules must allow UDP access over port 4500."
32,3,"You are migrating your production web application from your current Classic Load Balancer to an Application Load Balancer. Your current DNS service does not support weighting. You have already created the Application Load Balancer, configured it with settings that match your Classic Load Balancer configuration using the AWS Management console, and verified that the DNS name of the Application Load Balancer displays the default page of your server when pasted into a web browser. At this point, which of the following steps should you perform first?",Create a DNS record that associates your Application Load Balancer with your domain name,Update all CloudFormation templates to reference the Application Load Balancer instead of the Classic Load Balancer,Delete the Classic Load Balancer,Delete the DNS record that associates your Classic Load Balancer with your domain name ,1,"When migrating from a Classic Load Balancer to an Application Load Balancer, after creating the Application Load Balancer and confirming that it is functioning as expected by verifying that its DNS name resolves to the default page of your server, according to AWS documentation, the next step is to create a DNS record that associates your Application Load Balancer with your domain name and monitoring performance. "
33,3,"A customer currently has 3 VPCs in production using the same AWS account: VPC A, VPC B, and VPC C.The IPv4 address ranges for the VPCs are:VPC A 10.10.10.0/16VPC B 172.16.0.0/16VPC C 192.168.0.0/16VPCs B and C have both already been configured with a VPC peering connection that allows for connectivity to VPC A. There is now a need for network connectivity between multiple AWS resources on VPC B and VPC C. There is a requirement not to route the traffic over the Internet. Which of the following solutions will best meet the requirements?",Create a VPN connection between VPC B and VPC C,Create a VPC peering connection between VPC B and VPC C,Use a PrivateLink VPC Endpoint to connect VPC B to VPC C,Configure no additional connections and use transitive routing through VPC A to allow connectivity between the resources on VPC B and VPC C,2,"To configure full mesh connectivity between 3 VPCs using VPC peering, each VPC will require a VPC peering connection with the other two VPCs. Transitive routing is not supported with VPC peering. By definition, a VPN connection would route traffic over the Internet. EIC Endpoints are ideal for establish SSH connections from IP addresses on the public internet."
34,3,"A customer currently has an AWS partner-managed MPLS network they would like to connect their AWS resources to using Direct Connect (DX) connections. The AWS partner offers a hosted solution that can directly connect individual VPCs to the MPLS network using DX. However, the customer would like flexibility to create, delete, and configure VPCs without the need to engage the AWS partner every time a connection change or addition needs to occur. You are tasked with architecting a solution that allows the customer to achieve the goal of connecting VPCs to their partner-managed MPLS network using a DX connection while minimizing the need to engage the partner when connections are added or removed. Which solution best meets the requirements?",Create VPN connections between each VPC and the customer’s on-premises locations that are connected to the MPLS network,Create a Transit VPC that connects to the hosted DX connection from the AWS partner and provision other VPCs as needed to connect to the Transit VPC using Virtual Private Gateways,Provision enough VPCs to account for future growth now and use the hosted DX connection on each VPC,Create a Transit VPC that connects to the hosted DX connection from the AWS partner and provision other VPCs as needed to connect to the Transit VPC using VPC Peering,2,"Transit
VPCs allow customers to have flexibility in the creation, modification, and
deletion of VPCs while still maintaining a hosted DX connection to a partner
managed MPLS. Transit VPCs leverage virtual private gateways to connect to
other VPCs as VPC Peering would not allow for use of the DX connection.
Solutions that use VPN in place of DX would not meet the requirement of using a
DX connection. While provisioning extra VPCs and using a hosted DX connection with each would meet the connectivity requirement, it is an inflexible solution that wastes resources."
35,3,"A customer has reported that charges for data transfers have been higher than expected for traffic from their VPC to their on-premises network. Their in-house network engineers configured a DX connection between their VPC and on-premises network as well as a VPN connection for failover. The VPC IPv4 address range is 172.18.0.0/16. The on-premises network IPv4 address range is 172.16.0.0/16. Below are the current entries in the VPC’s routing table:
Destination                         Target
172.18.0.0/16                     local
172.16.0.0/16                     dxcon-exexexex
172.16.0.0/17                     vgw-abababab
10.20.30.0/24                     pcx-acacacac
Which of the following actions would be most likely to reduce the customer’s data transfer costs?",Remove route table entry with Destination: 10.20.30.0/24 Target: pcx-acacacac,Remove the route table entry with Destination: 172.16.0.0/17 Target: vgw-abababab,Add the route table entry with Destination: 172.16.0.0/16 Target: vgw-abababab,Remove the route table entry with Destination: 172.16.0.0/16 Target: dxcon-exexexex,2,"AWS will use the most specific route to route traffic from a VPC. Connections that begin with the prefix “vgw” are used for Virtual Private Gateway connections (which are used to establish VPN connections). Connections that begin with the prefix “dxcon” are used for Direct Connect (DX) connections. Connections that begin with the prefix “pcx” are used for VPC Peering connections. In this example, the route entry with Destination: 172.16.0.0/17 Target: vgw-abababab is the most specific route to the customer’s on-premises network, meaning any traffic originating in the VPC destined for IP addresses 172.16.0.0 - 172.16.127.255 (half of the customer’s IP address range in total) will be routed through the VPN connection. With DX data transfer rates being lower than VPN data transfer rates, removing that entry would be likely to lower data transfer costs moving forward."
36,3,A client has requested you to maximize throughput to their VPC  which is currently accessed via one 10GB Direct Connect (DX) connection. 8 ports are available at the Direct Connect Endpoint. The client is open to spending more to improve performance. Which of the following options best meets the requirement of maximizing throughput to the VPC?,Create a LAG using 3 additional 10GB connections and 4 additional 1GB connections,Create a LAG using 3 additional 10GB connections,Upgrade to a 40GB DX connection and create a LAG using 4 40GB connections,Create a LAG using 7 additional 10GB connections ,2,"All connections in a link aggregation group (LAG) must be the same bandwidth. A LAG only supports 1GB or 10GB speeds. A LAG supports up to 4 connections total. In this scenario, a LAG using 3 additional 10GB connections, for 4 total, is the only feasible solution listed."
37,3,You are creating IPv4 subnets within a VPC for a customer. The customer has a requirement to use IP addresses as efficiently as possible within each subnet. Which CIDR range should you use for a subnet that will contain 14 EC2 instances with each EC2 instance requiring 1 IPv4 address? ,/29,/28,/27,/26,3,"While /28 (16 addresses) would allow for 14 hosts normally, AWS reserves 5 IP addresses that cannot be assigned to an instance (as opposed to the 2 that are normally reserved). Given that, /27 (32 addresses) is the option that would allow for 14 instances to receive IP addresses while minimising wasted addresses. "
38,3,You have a 1000BASE-LX DX connection from your datacenter to a service provider’s location. You are unable to establish a connection to your VPC through the connection. You notice that the link lights are NOT lit on the 1000BASE-LX device in your datacenter. Which of the steps would NOT be helpful in troubleshooting the issue?,Turn on Auto Negotiation on the 1000BASE-LX device in your datacenter,Verify on-site cabling with the service provider,Set the port to Full Duplex on the 1000BASE-LX device in your datacenter,Set the port to 1GB speed on the 1000BASE-LX device in your datacenter,1,Auto Negotiation should be turned off for DX connections. It is possible an issue with the hardware at your service provider’s location is creating the problem so asking them to verify cabling is a valid troubleshooting step. The port on your device should be set to Full Duplex and match the speed of your connection (in this case the connection is 1000BASE-LX which is equivalent to 1GB).
39,3,"Your company was recently suffered a security breach. Since then you have implemented more restrictive policies both on-premises and in AWS. In addition to the NACL, IAM, and security group policies you have put in place, you would like to be alerted if there are 5 rejected SSH attempts to your EC2 instance with an ENI within any given hour. You will configure a CloudWatch Metric Filter and Alarm for a Flow Log to achieve this requirement. Which of the following should NOT be part of your Filter Pattern?","action=""REJECT""","destport=""22""","protocol=""6""","action=""ALARM""",4,"The alarm for a metric filter in CloudWatch is configured separately from the filter pattern. The “action” value in a filter pattern refers to what happened to the network traffic. In this example, you are looking for traffic that has been rejected, so you should filter for “REJECT”. For SSH connections, the “dstport” value should be “22” (the default SSH port) and the “protocol” value should be “6” (TCP). This only leaves the remaining option as the correct choice."
40,3,Your company has VPCs in two separate accounts in the same AWS region. You are tasked with establishing a VPC Peering connection between VPCs in the two accounts. Which of the following would be required to achieve this task?,Deploy VGWs on a VPC in each account,Authorize each account in the same AWS CloudFormation stack,Deploy software VPN instances on a VPC in each account,Authorize each account in the separate AWS CloudFormation stacks,2,"To peer VPCs in different accounts, you must authorize each account in the same AWS CloudFormation stack. Virtual Private Gateway (VGWs) and software VPNs are not required for VPC Peering connections."
41,3,You are testing a Classic Load Balancer that is distributing traffic to 4 EC2 instances. You are using Apache Bench to perform a single client test. You ramp the load at a rate of 25% every five minutes. The load test fails and you notice that traffic was only routed to one of the EC2 instances. What is the most likely reason for the failure?,You did not pre-warm the load balancer,Sticky sessions are enabled on the load balancer,Apache Bench is incompatible with Classic Load Balancers,No health checks were enabled on the other 3 instances,2,"Sticky sessions being enabled would cause all requests from a single client to be routed to the same backend server. If sticky sessions are enabled, testing of a load balancer should be performed with multiple clients. Apache Bench is a popular load testing tool and is not inherently incompatible with Classic Load Balancers. While pre-warming a load balancer and properly configuring health checks are important parts of testing an ELB, the symptom described is not indicative of a failure to do so."
42,3,"A customer currently has 3 VPCs in production using the same AWS account: VPC A, VPC B, and VPC C.The IPv4 address ranges for the VPCs are:VPC A 10.10.10.0/16VPC B 172.16.0.0/16VPC C 192.168.0.0/16VPCs B and C have already been configured with a VPC peering connection to VPC A. There is now a need for Linux instances on VPC B to access Linux instances on VPC C. There is a requirement not to route the traffic over the Internet. The customer would like to leave VPC B and VPC C otherwise logically isolated.Which option below best meets the requirements?",Use EC2 Instance Connect Endpoint to connect VPC B to VPC C,Use VPC peering to connect VPC B to VPC C,Use a PrivateLink VPC Endpoint to connect VPC B to VPC C,Configure no additional connections and use transitive routing through VPC A to allow connectivity between the resources on VPC B and VPC C,3,"In this scenario,  a “jump server” or Bastion host would be helpful as it would allow instances in VPC B to leverage the connectivity they have in VPC A to achieve the goal of SSH access to instances on VPC C.  Transitive routing is not supported with VPC peering. By definition, a VPN connection would route traffic over the Internet.   A  VPC Peering between VPC B and VPC C would not meet the requirement of leaving VPC B and VPC C otherwise logically isolated."
43,3,"Your team has recently performed an audit of the security of the network and infrastructure and it was discovered that you have some EC2 instances that have unintended network exposure. Since this was only discovered during a routine audit of the network and infrastructure security, you need to create a better way to have visibility into EC2 instances that have network reachability in the future. Which solution will allow you to have visibility into any EC2 instances that have network reachability in the future? ","Enable Amazon CloudSearch for the EC2 instances, view findings for your environment in the Amazon CloudSearch console.","Enable AWS Macie for the EC2 instances, view findings for your environment in the Amazon Macie console.","Enable AWS Application Discovery Service for the EC2 instances, view findings for your environment in the Amazon Application Discovery console.",Enable Amazon Inspector for the EC2 instances and view findings for your environment in the Amazon Inspector console.,4,"AWS Inspector can scan your EC2 instances for network exposure and generate findings that are viewable in the AWS Inspector dashboard. Network reachability findings indicate that there are allowed network paths to Amazon EC2 instances in your environment. These findings appear when your TCP and UDP ports are reachable from a VPC edge such as an internet gateway. These findings highlight network configurations that may be overly permissive, such as mismanaged security groups, ACLs, or IGWs, or that may allow for potentially malicious access.The remaining choices are incorrect for the following reasons:Amazon CloudSearch is a service used to make it easy to set up, manage, and scale a search solution for your website or application. Amazon CloudSearch does not scan EC2 instances for network reachability.AWS Macie is a service for the purpose of protecting sensitive data in AWS. AWS Macie can not be used to scan EC2 instances for network reachability.AWS Application Discovery Service helps enterprise customers plan migration projects by gathering information about their on-premises data centers. "
44,3,You are the network engineer responsible a VPN connection between a VPC’s virtual private gateway (VGW) and your on-premises VPN device (customer gateway). You are attempting to establish the IPsec tunnel between the two devices. Your customer gateway is on the AWS list of “Customer Gateway Devices We've Tested”. NAT-T is not being used. You have configured both the VGW and customer gateway and are now attempting to establish the IPsec tunnel between them. Phase 1 of the IKE exchange fails. You have ruled out incompatible IKE versions or encryption methods as the cause. Which option below could be creating the failure?,Your ISP is blocking inbound connections to TCP port 500,Your ISP is blocking outbound connections to UDP port 4500,Your ISP is blocking inbound connections to UDP port 500,Your ISP is blocking outbound connections to TCP port 4500,3,UDP port 500 needs to be open between a VGW and customer gateway for an IPsec tunnel to be established. Port 4500 is only required if using NAT-T.
45,3,"Your website, www.yoursite.net, contains links to videos stored in your S3 bucket. You need to allow read access to videos from www.yoursite.net, but would like to ensure that the requests are only authorized for your website. You will use a bucket policy to configure access. Which of the following should NOT be part of your bucket policy?"," ""StringLike"":{""aws:Referer"":[""http://www.yoursite.net/*"",""http://yoursite.net/*""]}","""Effect"":""Allow""","""Principal"":""*""","""Action"":""s3:PutObject""",4,"The website does not require write access or the ability to load files to the S3 bucket, therefore the ""Action"":""s3:PutObject"" should not be part of the bucket policy. Below is an example policy that would achieve the desired configuration:
{  ""Version"":""2012-10-17"",  ""Id"":""http referer policy example"",  ""Statement"":[    {      ""Sid"":""Allow get requests originating from www.yoursite.net and yoursite.net."",      ""Effect"":""Allow"",      ""Principal"":""*"",      ""Action"":""s3:GetObject"",      ""Resource"":""arn:aws:s3:::yourbucket/*"",     ""Condition"":{                 ""StringLike"":{""aws:Referer"":[""http://www.yoursite.net/*"",""http://yoursite.net/*""]}      }    }  ]}"
46,3,Your company has a customer gateway (CGW) that you will be using to connect to two separate VPCs via VPN. There are overlapping private IP address ranges on the two VPCs. You need to mitigate the potential issues that can occur when overlapping IP address ranges exist on a routing table. Which solution best meets the objective?,Use VRF on the CGW,Change the AS number of the CGW,Peer the VPCs and connect the CGW to one VPC only,Use DX to connect the VPCs and connect the CGW to one VPC only,1,"Virtual Routing and Forwarding (VRF) is a technology that allows multiple instances of a routing table to co-exist within the same router at the same time. Because the routing instances are independent, the same or overlapping IP addresses can be used without conflicting with each other."
47,3,"Your customer is designing a VPC to host a web application and database. They would like to add IPv6 support both for the web application and database. The VPC is split into two subnets. Subnet 1 hosts a web server with an IP address range of 10.100.100.0/24 and hosts the web application instance with a Private IPv4 address of 10.100.100.5 and an Elastic IP (EIP) of 198.15.200.6. Currently, outbound IPv4 Internet traffic is routed through a NAT Gateway on Subnet 1. The web application will need outbound IPv6 access and allow anyone to establish an HTTP or HTTPS session to the server. Which of the following solutions best meets the requirements for Subnet 1?","Enable IPv6 on the NAT Gateway, add a static route pointing all IPv6 traffic to the NAT Gateway, and add rules to the web application instances’ security group  that allow traffic from ::/0 to access TCP ports 80 & 443","Add an Internet Gateway (IGW) to the account, add a static route pointing all IPv6 traffic to the IGW, add rules to the web application instances’ security group that allows inbound traffic from ::/0 to TCP ports 80 & 443","Add an Internet Gateway (IGW) to the account, add a static route pointing all IPv6 traffic to the IGW, add rules to the web applications’ instance that allow outbound traffic from ::/0 to access TCP port 80 & 22","Enable IPv6 on the NAT Gateway, add a static route pointing all IPv6 traffic to the NAT Gateway, add rules to the web application instances’ security group that allows inbound traffic from ::/0 to TCP ports 80 & 443",2,NAT Gateways do not support IPv6. IGWs support both IPv4 and IPv6. The default HTTP and HTTPS ports are TCP ports 80 and 443. 
48,3,You are deploying an EC2 instance in your VPC that requires a static public IPv4 that can be reassigned to another instance in the event of a failure. Which of the following solutions will allow you to meet this requirement?,Elastic IP Address,Elastic Load Balancer,Auto Scaling,Internet Gateway,1,"Elastic IP Addresses are static public IPv4 addresses that are associated with an account, not a specific instance. Since the IP address is associated with the account and not a specific instance, failures of instances can be masked by remapping the IP address to another instance. "
49,3,"Users from all over the world visit your website. To improve their experience while on the site, you enabled Geolocation routing in Route 53. You specified specific ELBs for the EU, the United States, and Australia. After doing this, users from Canada were unable to connect to your site. What should you do to resolve the issue and mitigate the likelihood of it reoccurring?",Create a default record,Enable EDNS0,Specify an ELB for Canada,Specify an ELB for North America,1,"When using Geolocation routing, if you want users from unspecified regions or with IP addresses that cannot be reconciled to a location to be able to access your site, you need to create a default record. Specifying an ELB for Canada or North America would resolve the immediate issue, but given that your site has visitors from all over the world, the issue would be likely to reoccur. Using EDNS0 would potentially improve the accuracy of Geolocation routing, but would not route users to a default site or resolve issues with users who access the site from unspecified regions or with IP addresses that cannot be reconciled to a location."
50,3,"You are responsible for launching your company's website. The backend consists of multiple EC2 instances, and mutual TLS (mTLS) authentication using a backend certificate is a requirement.  You will be using CloudFront as a CDN, and there is a need to restrict access to individual PDF and MP4 files so that only certain users can access them. You have not yet determined a load-balancing strategy.Which of these options best meets the requirements?",Application Load Balancer and Signed Cookies,Gateway Load Balancer and Signed URLs ,Network Load Balancer and Signed URLs,Application Load Balancer (ALB) and Signed URLs,1,"Application Load Balancer (ALB) supports mutual TLS (mTLS) at the listener level, making it the best option in this scenario for handling backend authentication with certificates.Gateway Load Balancer (GWLB) and Signed URL is incorect. GWLBs are designed for third-party security appliances (firewalls, IDS/IPS, etc.), not for handling application traffic or mTLS authentication.  Signed URLs are useful for restricting file access but do not solve the mTLS authentication issue for backend EC2 instances.NLB operates at Layer 4 (TCP/UDP) and does not support mutual TLS authentication at the application layer. While Signed URLs can help restrict file access, NLBs do not provide application-layer authentication, making them unsuitable for this scenario.Application Load Balancer (ALB) and Signed URLs is incorrect. ALB is the right choice for mTLS, but Signed URLs are not the best choice for access restriction in this case. Signed Cookies are the preferred method when restricting access to multiple files per session, whereas Signed URLs are better for controlling access to single-use file downloads."
51,3,A customer has EC2 clusters deployed in private subnets within VPCs in the Asia Pacific (Tokyo) and US West (Oregon) regions. They would like to establish connectivity between the clusters while minimizing the amount of traffic that traverses the public Internet. Which of the following should be implemented in each region to meet the requirements?,"VGWs, software VPN instances, and public VIFs",CloudFront and Private VIFs,"IGWs, software VPN instances, and EIPs",VPC endpoints and Private VIFs,3,"Software VPN solutions can be used in conjunction with Internet Gateways (IGWs) and Elastic IPs (EIPs) to connect VPCs in different regions. By default in this configuration, AWS will route traffic over the AWS private network infrastructure, as opposed to the public Internet, on a best effort basis. CloudFront is a CDN technology. Virtual Private Gateways (VGWs) are used to connect VPCs to other VPN devices, but not to other VGWs."
52,3,"A client has requested that you configure an Active/Passive Direct Connect (DX) configuration for them between their VPC and on-premises datacenter so that the secondary DX connection is used only as a failover connection. You have already configured two routers to terminate the primary and secondary DX connections, a private virtual interface that terminates each of the routers for the DX to the same VPC, and iBGP on the routers to ensure that if the primary router fails the secondary router will take over. Which of the following steps are required to complete the Active/Passive DX configuration in this scenario? ","No action is required, Active/Passive is the default configuration",Configure MED to make the active link the preferred route,Use AS path prepending to make one of the links the passive link,Set the “passive” attribute on the link that is to serve as the Passive link using the AWS CLI or AWS Console,3,"By default, DX connections are Active/Active. The preferred method to make a link passive is to AS path prepend routes on the link. While the AWS CLI and AWS Console are common methods used to provision resources, the “passive” attribute referenced here was made up for use in this question."
53,3,"AWS uses a shared responsibility security model. This means AWS and AWS customers share responsibility for keeping resources secure, with each party being responsible for certain assets. For infrastructure services like EC2, which of the following assets are AWS customers responsible for?",Security of Data Center Facilities,Security of Server Hardware,Security of Network Cables and Switches,Security of Amazon Machine Images (AMIs),4,"According to an August 2016 AWS whitepaper, AWS uses a shared responsibility security  model. This means AWS and AWS customers share responsibility for keeping resources secure,  with each party being responsible for certain assets. For infrastructure services like EC2, AWS manages security for these assets:
• Facilities
• Physical security of hardware
• Network infrastructure
• Virtualization infrastructure
AWS customers are responsible for the security of these assets:
• Amazon Machine Images (AMIs)
• Operating systems
• Applications
• Data in transit
• Data at rest
• Data stores
• Credentials
• Policies and configuration"
54,3,You are deploying WorkSpaces for your company. Your management team requires all users to authenticate using an on-premises Active Directory (AD) server and no AD data is cached in AWS. You have a DX connection to your on-premises network and you have created a VPC with two private subnets in two AZs for Workspaces. Which of the following will be best suited to help complete the configuration?,AD Connector and DHCP options for the VPC configured to assign on-premises DNS servers,Simple AD and DHCP options for the VPC configured to assign the default Amazon DNS Servers,Microsoft AD and an EC2 instance running a replica of the on-premises DNS servers,AD connector and an EC2 instance running a replica of the on-premises DNS servers,1,"AD Connector does not cache AD data. In order to reliably use the on-premises AD servers, WorkSpaces should be configured to use the on-premises DNS servers. Both Simple AD and Microsoft AD would require data to be stored within AWS. Replicating the on-premises DNS servers is not ideal in this use case. "
55,3,"A client has a Classic Load Balancer named “client-lb” configured to distribute incoming requests across 10 instances in the us-east-1a AZ and 5 instances in the us-east-1b AZ. The client has a requirement for the incoming requests to be distributed equally across all 15 instances. Using the AWS CLI, which command below could be used to meet this requirement?","aws elb modify-load-balancer-attributes --load-balancer-name client-lb --load-balancer-attributes ""{\""ConnectionDraining\"":{\""Enabled\"":true,\""Timeout\"":300}}""","aws elb create-load-balancer --load-balancer-name client-lb --listeners ""Protocol=HTTP,LoadBalancerPort=80,InstanceProtocol=HTTP,InstancePort=80"" --availability-zones us-east-1a us-east-1b","aws elb create-load-balancer --load-balancer-name client-lb --listeners ""Protocol=HTTP,LoadBalancerPort=443,InstanceProtocol=HTTP,InstancePort=443"" --availability-zones us-east-1a us-east-1b","aws elb modify-load-balancer-attributes --load-balancer-name client-lb --load-balancer-attributes ""{\""CrossZoneLoadBalancing\"":{\""Enabled\"":true}}""",4,"Cross-Zone Load Balancing distributes incoming requests evenly across all enabled Availability Zones. This reduces the need to have equal numbers of instances in all Availability Zones and improves the ability of an application to deal with the loss of instances. The ""modify-load-balancer"" can be used in conjunction with the --load-balancer-attributes option and ""{\""CrossZoneLoadBalancing\"":{\""Enabled\"":true}}"" variables to enable Cross-Zone Load Balancing on an existing Classic Load Balancer. "
56,3,"When an Amazon Virtual Private Cloud (VPC) is created, Amazon automatically creates a set of DHCP options. One of the options is AmazonProvidedDNS which maps an AWS-managed DNS server to an IPv4 address that is reserved at the base of the VPC’s IPv4 network range, plus two. Given this information, what would be the IP address for the AWS-managed DNS server in a VPC with a network range of 10.20.30.0/24?",10.20.32.1,10.20.32.0,10.20.30.2,10.20.30.1,3,"By default, the Amazon provided DNS server in a VPC is given the IPv4 address at the base of the VPC’s IPv4 network range, plus two. Given a network range of 10.20.30.0/24, the base is 10.20.30.0. Adding two to the base, we get 10.20.30.2. "
57,3,"A customer needs to allow EC2 instances deployed across 3 VPCs (VPCs A, B, & C) access to DNS servers at an on premises datacenter. The customer has the required hardware to establish a VPN connection, but would like to minimize the traffic over the VPN. Which of the solutions below best meets the requirements described?","Configure a Transit VPC with an EIP and IGW to connect to the data center, create VPN connections between the Transit VPC the VPCs A, B, & C, and use dynamic routing to allow the VPCs A, B, & C to access the DNS server at the data center","Configure a VPC with a VPN connection through a VGW, replicate the data center’s DNS services on this VPC, and establish VPC Peering connections between this VPC and VPCs A, B, & C allowing VPCs A, B, & C to access the replicated DNS server","Configure a Transit VPC with an EIP and IGW to connect to the data center, create VPC Peering connections between the Transit VPC the VPCs A, B, & C, and use dynamic routing to allow the VPCs A, B, & C to access the DNS server at the data center","Configure a VPC with a VPN connection through a VGW, establish VPC Peering connections between this VPC and VPCs A, B, & C,  and create static routes to allow the VPCs A, B, & C to access the DNS server at the data center",2,"This
configuration is sometimes referred to as a “Shared Services” VPC. Shared
Services VPCs are advantageous when users wish to limit VPN traffic and the
on-premises resources are easily replicated or proxied (Active Directory, DNS
etc). Creating a Transit VPC with an EIP and IGW and establishing VPN
connections between that VPC and VPCs A, B, & C would allow for the
required connectivity but would not minimize VPN traffic. VPC Peering could not
be used to allow direct connections to the data center as VPC Peering does not
allow transitive routing. "
58,3,You are configuring Amazon Route 53 to route traffic destined for yourwebsite.com to an Application Load Balancer that is configured to distribute IPv4 traffic in two availability zones in the same AWS region. Which record set should you edit to point traffic for yourwebsite.com to your Application Load Balancer? Select the answer that is the most cost-effective and scalable.,Alias,CNAME,AAAA,MX,1,"yourwebsite.com  is a zone apex. Alias record sets can be used to set a zone apex, but CNAME records cannot. Additionally, queries to Alias records that are mapped to an ELB are free. A records are used to map IPv4 addresses to FQDNs, the IP address of the ELB may change. MX records are used for email servers."
59,3,"Assuming the user has the appropriate access, rule number 100 does not already exist, and acl-12345 is a valid network ACL, what does the AWS CLI command below do?
aws ec2 create-network-acl-entry --network-acl-id acl-12345 --ingress --rule-number 100 --protocol udp --port-range From=53,To=53 --cidr-block 0.0.0.0/0 --rule-action allow",Allow inbound traffic from all IPv4 addresses on the default SFTP port,Allow outbound traffic to all IPv4 addresses on the default DHCP port,Allow inbound traffic from all IPv4 addresses on the default DNS port,Allow inbound traffic from all IPv4 addresses on the default RDP port,3,"The “create-network-acl-entry” AWS CLI command creates a rule in a network ACL. Ingress rules are for inbound traffic. Egress rules are for outbound traffic. By default, DNS uses UDP port 53."
60,3,"You have a DX connection between your on-premises network and your VPC. Your on-premises IP address range is 172.16.0.0-172.16.1.255. There are multiple subnets across 2 AZs in your VPC. Subnet A in your VPC has an IP address range of 10.20.30.0-10.20.30.255. Subnet B has an IP address range of 10.20.40.0-10.20.40.255. Subnet A hosts a number of Windows EC2 instances that require outbound Internet access through a NAT gateway hosted in Subnet B, must be accessible via RDP from your on-premises network, and should allow no other inbound traffic other than what is necessary to meet these requirements. Which of the following should NOT be an IPv4 rule in the NACL for Subnet A?",An Inbound ALLOW rule with a source IP of 0.0.0.0/0 for TCP ports 1024-65535,An Outbound ALLOW rule with a destination of 0.0.0.0/0 for all protocols and all ports,An Inbound ALLOW rule with a source IP of 172.16.0.0/24 for TCP port 3389,An Inbound ALLOW rule with a source IP of 172.16.0.0/23 for TCP port 3389,3,The correct response is An Inbound ALLOW rule with a source IP of 172.16.0.0/24 for TCP port 3389 because it is NOT an IPv4 rule in the NACL for Subnet A.The Inbound ALLOW rule with a source IP of 0.0.0.0/0 for TCP ports 1024-65535 and the outbound ALLOW rule with a destination of 0.0.0.0/0 for all protocols and all ports would allow for Internet access (the inbound rule is required for return traffic on ephemeral ports). The allow rule for RDP access from the on-premises network should use a /23 CIDR range to account for all the IP addresses in the 172.16.0.0-172.16.1.255 range.
61,3,A customer would like to optimize the performance of their web application by routing inbound traffic to customersite.net/api to Compute Optimized EC2 instances and inbound traffic to customersite.net/mobile to Memory Optimized EC2 instances. Which solution below would be best to implement for this customer?,Configure proxy servers to forward the traffic to the correct instances,Use an Application Load Balancer with host-based routing rules to forward the traffic to the correct instances,Use an Application Load Balancer with path-based routing rules to forward the traffic to the correct instances,Enable X-Forwarded For on the web servers and use a Classic Load Balancer ,3,"Application Load Balancers support both path-based and host-based routing. Path-based routing takes into account the path in the URI (i.e. /2017/july/blogs or in this case /api and /mobile) and allows rules to be configured that would allow traffic to be forwarded as required in this example. Application Load Balancers can be used with host-based routing rules to route traffic by subdomain names, not URI paths. Proxy servers could be used to achieve the desired functionality, but are less efficient. X-Forwarded For would not be helpful in forwarding traffic to specific instances."
62,3,Your customer would like to migrate the DNS service for the subdomain “mobile.customersite.com” to Route 53 without migrating the DNS service for “customersite.com” or any other subdomains. Which of the following would not be one of the steps required for completing the process?,Creating a Route 53 hosted zone for “mobile.customersite.com”,Adding resource record sets for “mobile.customersite.com” to a Route 53 hosted zone,Updating the DNS configuration for “customersite.com” by adding name server records for “mobile.customersite.com”,Adding a start of authority record to the zone file for “customersite.com” ,4,"Adding a start of authority record to the zone file of a parent domain would not be required when migrating a subdomain to Route 53 since the parent domain will not be the authority of the subdomain. To migrate a subdomain to Route 53, you must create a hosted zone for the subdomain, add resource record sets for the subdomain to the hosted zone, and update the DNS configuration of the parent domain with name server records for the subdomain."
63,3,"Your company has 3 VPCs, VPC A, VPC B, and VPC C. All 3 VPCs require IPv4 connectivity.
VPC A has an IPv4 address range of 172.24.0.0/16
VPC B has an IPv4 address range of 172.30.0.0/16
VPC C has an IPv4 address range of 10.20.0.0/16
VPC A is peered to VPC B using a VPC Peering connection named pcx-abababab
VPC A is peered to VPC C using a VPC peering connection named pcx-acacacac
Which of the following static routes could be added to VPC B’s routing table to allow traffic originating in VPC B to reach VPC C?",Destination: pcx-abababab Target: 10.20.0.0/16,Destination: 10.20.0.0/16 Target: pcx-abababab,Destination: pcx-abababab Target: pcx-acacacac,None of the options available are valid,4,"VPC Peering does not support transitive routing. In this example, that means that VPC B cannot reach VPC C using connections to VPC A. A new VPC Peering connection must be used to connect VPC B and VPC C."
64,3,"You have configured an Active/Passive Direct Connect (DX) connection for a customer between their VPC and on-premises datacenter. You have already configured two routers to terminate the primary and secondary DX connections, a private virtual interface that terminates each of the routers for the DX to the same VPC, and iBGP on the routers to ensure that if the primary router fails the secondary router will take over, and used AS path prepending to make one of the links the passive link. Connectivity between resources in the customer’s VPC and on-premises datacenter works as expected, but after testing failover the customer complains that it takes too long for the passive link to activate. What could be enabled to make the failover faster?",BFD,OSPF,eBGP,VPC Peering,1,"Bidirectional Forwarding Detection (BFD) is a network fault detection protocol that helps detect network failures quickly and can be leveraged to improve failover times in Active/Passive DX connections. AWS recommends enabling BFD when using multiple DX  connections or a DX connection and a VPN connection to speed up failover times. OSPF is an interior routing protocol. eBGP is External BGP, which is the Internet facing version of BGP. VPC Peering is used to connect two VPCs."
65,3,You are using auto scaling EC2 instances that serve as the front end of a web application based on CPU utilization. The additional instances terminate when CPU utilization stabilizes. You would like to download application log files from the instance before it terminates. Which of the options below would allow you to reliably retrieve the application log files before instances terminate?,Lifecycle hooks,Auto scaling cooldowns,The rds-download-db-logfile AWS CLI command,CloudTrail,1,"Lifecycle hooks allow you to execute custom actions as auto scaling launches or terminates instances and would be best suited to meet the requirement in this scenario. Auto scaling cooldowns are a wait period before a subsequent auto scaling action occurs. The rds-download-db-logfile AWS CLI command is specific to RDS. CloudTrails used to log and continuously monitor events related to API calls, and would not be helpful in downloading application specific log files in this scenario. "
